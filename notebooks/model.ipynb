{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cc76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# STACKED NDAE (greedy layer-wise AE pretraining) + RandomForest\n",
    "# ---------------------------\n",
    "# Run in notebook cell. Change paths if file names differ.\n",
    "# ---------------------------\n",
    "\n",
    "# Install required packages (uncomment if needed)\n",
    "# %pip install tensorflow-cpu scikit-learn imbalanced-learn pandas numpy --quiet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1efcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "\n",
    "# ---------------------------\n",
    "# Paths - change if needed\n",
    "# ---------------------------\n",
    "TRAIN_PATH = \"../data/nsl-kdd/KDDTrain+.txt\"\n",
    "TEST_PATH  = \"../data/nsl-kdd/KDDTest+.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b1c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) Column names for KDD/NSL-KDD\n",
    "# ---------------------------\n",
    "columns = [\n",
    "    'duration','protocol_type','service','flag','src_bytes','dst_bytes','land',\n",
    "    'wrong_fragment','urgent','hot','num_failed_logins','logged_in',\n",
    "    'num_compromised','root_shell','su_attempted','num_root',\n",
    "    'num_file_creations','num_shells','num_access_files','num_outbound_cmds',\n",
    "    'is_host_login','is_guest_login','count','srv_count','serror_rate',\n",
    "    'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate',\n",
    "    'diff_srv_rate','srv_diff_host_rate','dst_host_count',\n",
    "    'dst_host_srv_count','dst_host_same_srv_rate','dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate','dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate','label','difficulty'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b443dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train shape: (125973, 43) Test shape: (22544, 43)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 2) Load dataset function (handles ARFF-like CSVs too)\n",
    "# ---------------------------\n",
    "def load_nsl_kdd(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{path} not found. Please upload KDDTrain+.txt / KDDTest+.txt to /mnt/data.\")\n",
    "    df = pd.read_csv(path, names=columns)\n",
    "    return df\n",
    "\n",
    "print(\"Loading data...\")\n",
    "train_df = load_nsl_kdd(TRAIN_PATH)\n",
    "test_df  = load_nsl_kdd(TEST_PATH)\n",
    "print(\"Train shape:\", train_df.shape, \"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e43ccc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3) Binary label: normal -> 0, others -> 1\n",
    "# ---------------------------\n",
    "for df in (train_df, test_df):\n",
    "    df['binary_label'] = df['label'].apply(lambda x: 0 if str(x).strip().lower() == 'normal' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139098ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 4) Encode categorical features (protocol_type, service, flag)\n",
    "# LabelEncoder is simpler and faster here (paper used feature selection)\n",
    "# ---------------------------\n",
    "cat_cols = ['protocol_type','service','flag']\n",
    "le_dict = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined to avoid unseen labels in test\n",
    "    combined = pd.concat([train_df[col].astype(str), test_df[col].astype(str)], axis=0)\n",
    "    le.fit(combined)\n",
    "    le_dict[col] = le\n",
    "    train_df[col] = le.transform(train_df[col].astype(str))\n",
    "    test_df[col]  = le.transform(test_df[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8a3998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using feature columns: 41\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 5) Feature selection - follow typical NSL-KDD: use all numeric + encoded categorical\n",
    "# Drop label & difficulty & binary_label from features\n",
    "# ---------------------------\n",
    "drop_cols = ['label','difficulty','binary_label']\n",
    "feature_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "print(\"Using feature columns:\", len(feature_cols))\n",
    "\n",
    "X_train_raw = train_df[feature_cols].copy()\n",
    "y_train = train_df['binary_label'].astype(int).copy()\n",
    "\n",
    "X_test_raw = test_df[feature_cols].copy()\n",
    "y_test = test_df['binary_label'].astype(int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5243b03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../backend/models/scaler_nslkdd.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 6) Scale features (fit on train only)\n",
    "# ---------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "X_test_scaled  = scaler.transform(X_test_raw)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, \"../backend/models/scaler_nslkdd.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ab10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer-wise pretraining of shallow autoencoders...\n",
      " Pretraining layer 1/3 -> hidden_dim=64\n",
      "Epoch 1/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6830\n",
      "Epoch 2/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2870\n",
      "Epoch 3/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1709\n",
      "Epoch 4/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1135\n",
      "Epoch 5/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0799\n",
      "Epoch 6/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0573\n",
      "Epoch 7/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0413\n",
      "Epoch 8/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0303\n",
      "Epoch 9/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0227\n",
      "Epoch 10/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176\n",
      "Epoch 11/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141\n",
      "Epoch 12/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119\n",
      "Epoch 13/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105\n",
      "Epoch 14/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097\n",
      "Epoch 15/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089\n",
      "\u001b[1m3937/3937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step\n",
      " Pretraining layer 2/3 -> hidden_dim=32\n",
      "Epoch 1/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6796\n",
      "Epoch 2/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3403\n",
      "Epoch 3/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2392\n",
      "Epoch 4/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1801\n",
      "Epoch 5/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1426\n",
      "Epoch 6/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1159\n",
      "Epoch 7/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0944\n",
      "Epoch 8/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0792\n",
      "Epoch 9/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0678\n",
      "Epoch 10/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0588\n",
      "Epoch 11/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0519\n",
      "Epoch 12/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0464\n",
      "Epoch 13/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0419\n",
      "Epoch 14/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0380\n",
      "Epoch 15/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0348\n",
      "\u001b[1m3937/3937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708us/step\n",
      " Pretraining layer 3/3 -> hidden_dim=16\n",
      "Epoch 1/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.2118 \n",
      "Epoch 2/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8965\n",
      "Epoch 3/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6356\n",
      "Epoch 4/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5281\n",
      "Epoch 5/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4647\n",
      "Epoch 6/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4198\n",
      "Epoch 7/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3857\n",
      "Epoch 8/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3574\n",
      "Epoch 9/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3327\n",
      "Epoch 10/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3100\n",
      "Epoch 11/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2880\n",
      "Epoch 12/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2681\n",
      "Epoch 13/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2524\n",
      "Epoch 14/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2386\n",
      "Epoch 15/15\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2269\n",
      "\u001b[1m3937/3937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 629us/step\n",
      "Pretraining complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 7) Stacked NDAE via greedy layer-wise pretraining\n",
    "#    We'll train a sequence of shallow autoencoders (encoder + decoder),\n",
    "#    keep the encoder part, transform data layer-by-layer to produce final code.\n",
    "#    This matches the \"stacked non-symmetric deep autoencoder\" pretrain approach.\n",
    "# ---------------------------\n",
    "\n",
    "def train_shallow_autoencoder(X, hidden_dim, epochs=10, batch_size=2048, lr=1e-3, verbose=0):\n",
    "    inp_dim = X.shape[1]\n",
    "    inp = Input(shape=(inp_dim,))\n",
    "    encoded = Dense(hidden_dim, activation='relu')(inp)\n",
    "    decoded = Dense(inp_dim, activation='linear')(encoded)\n",
    "    ae = Model(inp, decoded)\n",
    "    encoder = Model(inp, encoded)\n",
    "    ae.compile(optimizer=Adam(learning_rate=lr), loss='mse')\n",
    "    ae.fit(X, X, epochs=epochs, batch_size=batch_size, shuffle=True, verbose=verbose)\n",
    "    return ae, encoder\n",
    "\n",
    "# Network of hidden sizes (non-symmetric: gradually reduce)\n",
    "# You can tune this list. Paper used same neurons as features in NDAE layers; here we pick a decreasing configuration.\n",
    "hidden_layers = [64, 32, 16]  # final encoding_dim = 16\n",
    "X_current = X_train_scaled.copy()\n",
    "encoders = []\n",
    "\n",
    "print(\"Layer-wise pretraining of shallow autoencoders...\")\n",
    "for i, hdim in enumerate(hidden_layers):\n",
    "    print(f\" Pretraining layer {i+1}/{len(hidden_layers)} -> hidden_dim={hdim}\")\n",
    "    ae, enc = train_shallow_autoencoder(X_current, hidden_dim=hdim, epochs=15, batch_size=1024, lr=1e-3, verbose=1)\n",
    "    # store encoder model\n",
    "    encoders.append(enc)\n",
    "    # transform X_current for next layer (greedy stacking)\n",
    "    X_current = enc.predict(X_current)\n",
    "    # Save shallow AE and encoder\n",
    "    ae.save(f\"../backend/models/ae_layer_{i+1}.keras\", include_optimizer=False)\n",
    "    enc.save(f\"../backend/models/encoder_layer_{i+1}.keras\")\n",
    "print(\"Pretraining complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4b9746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked encoder built. Final code dim: (None, 16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 8) Build stacked encoder (compose encoders)\n",
    "# ---------------------------\n",
    "# Create a model that maps from original input to final code by applying each encoder sequentially.\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "stack_input = Input(shape=(input_dim,))\n",
    "x = stack_input\n",
    "for enc in encoders:\n",
    "    # each enc is a keras Model; call its internal layers on x by using enc.layers after input layer\n",
    "    # safer: use enc(x) because enc is a Model mapping input->hidden\n",
    "    x = enc(x)\n",
    "stacked_encoder = Model(stack_input, x)\n",
    "# Save stacked encoder\n",
    "stacked_encoder.save(\"../backend/models/stacked_encoder.keras\")\n",
    "print(\"Stacked encoder built. Final code dim:\", stacked_encoder.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4210246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3937/3937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 728us/step\n",
      "\u001b[1m705/705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step\n",
      "Encoded shapes: (125973, 16) (22544, 16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 9) Encode train and test sets to get compact representations\n",
    "# ---------------------------\n",
    "X_train_code = stacked_encoder.predict(X_train_scaled)\n",
    "X_test_code  = stacked_encoder.predict(X_test_scaled)\n",
    "print(\"Encoded shapes:\", X_train_code.shape, X_test_code.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3272710c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [67343 58630]\n",
      "After SMOTE: [67343 67343]\n",
      "Resampled shape: (134686, 16)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 10) Handle class imbalance with SMOTE on training codes\n",
    "# ---------------------------\n",
    "print(\"Before SMOTE:\", np.bincount(y_train))\n",
    "sm = SMOTE(k_neighbors=4, random_state=RANDOM_STATE)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_code, y_train)\n",
    "print(\"After SMOTE:\", np.bincount(y_train_res))\n",
    "print(\"Resampled shape:\", X_train_res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065cdf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest trained on encoded features.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 11) Train RandomForest on encoded features (use class_weight for robustness)\n",
    "# ---------------------------\n",
    "clf = RandomForestClassifier(n_estimators=400, class_weight={0:1, 1:6}, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "joblib.dump(clf, \"../backend/models/rf_encoded.joblib\")\n",
    "print(\"RandomForest trained on encoded features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79e5faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "THRESHOLD = 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6477    0.9797    0.7798      9711\n",
      "           1     0.9749    0.5967    0.7403     12833\n",
      "\n",
      "    accuracy                         0.7617     22544\n",
      "   macro avg     0.8113    0.7882    0.7600     22544\n",
      "weighted avg     0.8339    0.7617    0.7573     22544\n",
      "\n",
      "Confusion matrix:\n",
      " [[9514  197]\n",
      " [5176 7657]]\n",
      "ROC-AUC: 0.9417\n",
      "\n",
      "-----------------------------\n",
      "THRESHOLD = 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6634    0.9731    0.7890      9711\n",
      "           1     0.9686    0.6264    0.7608     12833\n",
      "\n",
      "    accuracy                         0.7758     22544\n",
      "   macro avg     0.8160    0.7998    0.7749     22544\n",
      "weighted avg     0.8371    0.7758    0.7729     22544\n",
      "\n",
      "Confusion matrix:\n",
      " [[9450  261]\n",
      " [4794 8039]]\n",
      "ROC-AUC: 0.9417\n",
      "\n",
      "-----------------------------\n",
      "THRESHOLD = 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6775    0.9713    0.7982      9711\n",
      "           1     0.9676    0.6501    0.7777     12833\n",
      "\n",
      "    accuracy                         0.7885     22544\n",
      "   macro avg     0.8226    0.8107    0.7880     22544\n",
      "weighted avg     0.8427    0.7885    0.7865     22544\n",
      "\n",
      "Confusion matrix:\n",
      " [[9432  279]\n",
      " [4490 8343]]\n",
      "ROC-AUC: 0.9417\n",
      "\n",
      "ROC curve summary: FPR@TPR=0.9 -> approx FPR: 0.1062\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 12) Prediction & Evaluation\n",
    "# ---------------------------\n",
    "probs_test = clf.predict_proba(X_test_code)[:,1]\n",
    "# Choose a threshold. We provide results for default 0.5 and a lowered 0.3 to favor recall.\n",
    "for threshold in (0.5, 0.3, 0.25):\n",
    "    y_pred_thr = (probs_test >= threshold).astype(int)\n",
    "    print(\"\\n-----------------------------\")\n",
    "    print(f\"THRESHOLD = {threshold}\")\n",
    "    print(classification_report(y_test, y_pred_thr, digits=4))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_thr))\n",
    "    try:\n",
    "        print(\"ROC-AUC:\", round(roc_auc_score(y_test, probs_test), 4))\n",
    "    except:\n",
    "        print(\"ROC-AUC: n/a\")\n",
    "\n",
    "# Also print ROC curve points (optional)\n",
    "fpr, tpr, _ = roc_curve(y_test, probs_test)\n",
    "print(f\"\\nROC curve summary: FPR@TPR=0.9 -> approx FPR: {np.interp(0.9, tpr, fpr):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab9bb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 13) Real-time detection function (uses saved scaler, stacked_encoder, clf)\n",
    "# ---------------------------\n",
    "def load_models(scaler_path=\"../backend/models/scaler_nslkdd.joblib\",\n",
    "                encoder_path=\"../backend/models/stacked_encoder.keras\",\n",
    "                rf_path=\"../backend/models/rf_encoded.joblib\"):\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    enc = tf.keras.models.load_model(encoder_path)\n",
    "    rf = joblib.load(rf_path)\n",
    "    return scaler, enc, rf\n",
    "\n",
    "scaler_loaded, encoder_loaded, rf_loaded = load_models()\n",
    "\n",
    "def detect_event(event_dict, threshold=0.3):\n",
    "    # Build dataframe row with all feature cols\n",
    "    row = {c: event_dict.get(c, 0) for c in feature_cols}\n",
    "    dfrow = pd.DataFrame([row])\n",
    "\n",
    "    # NO LABEL ENCODER HERE (values already numeric)\n",
    "    # Scale features\n",
    "    X_scaled = scaler_loaded.transform(dfrow[feature_cols].values)\n",
    "\n",
    "    # Encode with stacked encoder\n",
    "    code = encoder_loaded.predict(X_scaled)\n",
    "\n",
    "    # RF probability\n",
    "    prob = rf_loaded.predict_proba(code)[:,1][0]\n",
    "\n",
    "    return {\n",
    "        \"anomaly_score\": float(prob),\n",
    "        \"is_anomaly\": int(prob >= threshold)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da6eb8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\n",
      "Example detection result: {'anomaly_score': 0.0, 'is_anomaly': 0}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 14) Example usage\n",
    "# ---------------------------\n",
    "sample_event = dict(zip(feature_cols, X_test_raw.iloc[5].values))  # take a real row from test\n",
    "sample_event['src_bytes'] = float(sample_event['src_bytes']) * 4  # make it more 'suspicious'\n",
    "res = detect_event(sample_event, threshold=0.3)\n",
    "print(\"\\nExample detection result:\", res)\n",
    "\n",
    "# ---------------------------\n",
    "# Done. Models saved to /mnt/data (stacked_encoder.keras, rf_encoded.joblib, scaler_nslkdd.joblib, encoders/ae layers)\n",
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf0a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
